# 标签分类与抓取逻辑

本文档说明方矩研报的标签体系及各内容类型的抓取逻辑。

---

## 一、标签分类体系

标签定义在 `backend/tagging.py`，分为三类：

### 1. 论文标签（PAPER_TAG_KEYWORDS）

在 **title + abstract + categories + keywords** 中做不区分大小写的子串匹配：


| 标签 | 匹配关键词示例 |
|------|----------------|
| 3DGS | 3d gaussian, 3dgs, 4d gaussian, 4dgs, dynamic gaussian |
| 视频/世界模型 | world model, video generation, video synthesis |
| 3DGS物理仿真 | physics simulation, mpm, material point method |
| 具身智能 | embodied ai, robot, robotics |
| 多模态 | vision-language, vision language, vlm, visual language model, diffusion model, diffusion 3d, generative ai, 生成式ai |
| 3D重建/生成/渲染 | 3d reconstruction, 3d generation, 3d rendering |
| VR/AR | virtual reality, augmented reality |
| 可重光照/逆渲染 | relighting, relightable, relight, inverse rendering, inverse-rendering, inverse render, inverse-render, lighting editing, 光照编辑 |
| 3D人体/角色 | human avatar, character animation, 3d human |
| 3DGS编辑 | gaussian splatting edit, 3dgs edit |
| 3DGS水下建模 | underwater, 水下 |


### 2. 会议标签（CONFERENCE_TAG_KEYWORDS）

仅在 **categories + venue** 中匹配（避免 abstract 中提及会议误标）：


| 标签                 | 匹配关键词               |
| ------------------ | ------------------- |
| CVPR / ICCV / ECCV | cvpr, iccv, eccv    |
| ICLR / NeurIPS     | iclr, neurips, nips |
| SIGGRAPH           | siggraph            |


### 3. 社区/公司标签（POST_TAG_KEYWORDS）

与论文类似，但关键词更精简，并增加产品名（如 sora、runway、tripo、meshy 等）。

---

## 二、各内容类型的打标逻辑

### 1. 论文（tag_paper）

- **输入**：title, abstract, categories, keywords, source, venue
- **逻辑**：
  - 研究方向：在 title + abstract + categories + keywords 中匹配 PAPER_TAG_KEYWORDS
  - 会议标签：仅在 categories + venue 中匹配 CONFERENCE_TAG_KEYWORDS
  - 来源：根据 source 追加 ARXIV / OPENREVIEW / S2

### 2. 社区动态（tag_post）

- **输入**：title, summary, source, channel
- **逻辑**：
  - 在 title + summary 中匹配 POST_TAG_KEYWORDS
  - 根据 source 追加 HN / Reddit / GitHub / YouTube / Hugging Face
  - 若有 channel 则追加为标签

### 3. 公司动态（tag_company_post）

- **输入**：title, summary, channel（公司名）, author, company_directions
- **逻辑**：
  - 在 title + summary 中匹配 POST_TAG_KEYWORDS
  - 根据公司归属方向追加 3D重建/生成/渲染、视频/世界模型、3D设计、多模态、具身智能
  - 公司名、微信公众号作为额外标签

---

## 三、各内容类型的抓取逻辑

### 1. 论文（crawler.py）


| 数据源                  | 抓取方式                    | 关键词来源                               |
| -------------------- | ----------------------- | ----------------------------------- |
| **arXiv**            | 按标签搜索，每标签单独请求 + 分类限制 + 日期 | 11 个研究方向标签，每标签 10～20 篇（days=14，max_per_tag=20）。支持 `tag` 参数：选定标签时仅抓取该标签关键词 |
| **OpenReview**       | 按 venue 查 API，每会议 10～20 篇 | 仅 2025：ICLR、NeurIPS、CVPR、ICCV |
| **Semantic Scholar** | 按 query 搜索              | crawl_keywords → s2_queries → ARXIV_SEARCH_KEYWORDS → S2_DEFAULT_QUERIES |


**入库过滤**：论文必须有至少一个业务标签（研究方向或会议），否则不入库。

### 2. 代码动态（code_crawler.py）

| 数据源              | 抓取方式                    | 关键词                                                         |
| ---------------- | ----------------------- | ----------------------------------------------------------- |
| **GitHub**       | Search Repositories API | crawl_keywords(community) → ARXIV_SEARCH_KEYWORDS（与论文统一） |
| **Hugging Face** | Models API              | 同上                                                          |

**时间过滤**：支持 `days` 参数（近一月/近三月/全部）。GitHub 用 `created:>=YYYY-MM-DD`；Hugging Face 按 `sort=created` 抓取后客户端过滤。

**标签过滤**：支持 `tag` 参数。选定标签时，仅用 POST_TAG_KEYWORDS 中该标签对应的关键词抓取（选定标签→选定时间→抓取）。

**入库过滤**：无，全部入库。

### 3. 社区动态（community_crawler.py）

| 数据源         | 抓取方式                          | 关键词                                                         |
| ----------- | ----------------------------- | ----------------------------------------------------------- |
| **HN**      | Algolia API 搜索                | crawl_keywords(community) → ARXIV_SEARCH_KEYWORDS（与论文统一） |
| **Reddit**  | 子版块 /new.json                 | 固定：MachineLearning, computervision, LocalLLaMA           |
| **YouTube** | Search API（需 YOUTUBE_API_KEY） | 同上                                                          |

**时间过滤**：支持 `days` 参数（近一周/近两周/近一个月，7/14/30）。HN 用 numericFilters；Reddit/YouTube 客户端过滤。

**标签过滤**：支持 `tag` 参数。选定标签时，仅用 POST_TAG_KEYWORDS 中该标签对应的关键词抓取 HN、YouTube。Reddit 按子版块抓取无关键词搜索，按标签时跳过。

**来源过滤**：支持 `source` 参数（hn/reddit/youtube）。选定来源时，仅抓取对应平台。

**入库过滤**：无，全部入库。

### 4. 公司动态（company_crawler.py）


| 数据源                 | 抓取方式      | 关键词                           |
| ------------------- | --------- | ----------------------------- |
| **Google News RSS** | 按公司搜索 RSS | COMPANY_QUERIES（公司名 + 产品关键词）  |
| **微信公众号**           | RSSHub    | WECHAT_MP_ALBUMS 中配置的 biz/aid |


- 按 COMPANY_DIRECTIONS 中的公司列表并行抓取
- 支持 crawl_keywords(company) 作为额外 Google News 搜索词

**时间过滤**：仅抓取近 90 天（3 个月）。按 published_parsed 客户端过滤。

**入库过滤**：无，全部入库。

---

## 四、总结


| 内容类型 | 打标函数             | 入库过滤    | 存储表    |
| ---- | ---------------- | ------- | ------ |
| 论文   | tag_paper        | 必须有业务标签 | papers |
| 代码动态 | tag_post         | 无       | posts  |
| 社区动态 | tag_post         | 无       | posts  |
| 公司动态 | tag_company_post | 无       | posts  |


---

## 五、相关文件

- `backend/tagging.py` - 标签定义与打标函数
- `backend/crawler.py` - 论文抓取
- `backend/code_crawler.py` - 代码动态抓取（GitHub、Hugging Face）
- `backend/community_crawler.py` - 社区动态抓取（HN、Reddit、YouTube）
- `backend/company_crawler.py` - 公司动态抓取

